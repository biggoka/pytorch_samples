{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, capacity=10000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.short_memory = []\n",
    "        \n",
    "    def push(self, old_state, action, reward, new_state):\n",
    "        self.short_memory.append([old_state, action, reward, new_state, False])\n",
    "        \n",
    "    def commit(self, final=True): \n",
    "        \n",
    "        self.short_memory[-1][-1] = final\n",
    "        \n",
    "# #         discount\n",
    "#         for i, memo in enumerate(self.short_memory[::-1]):\n",
    "#             old_state, action, reward, new_state, *_ = memo\n",
    "            \n",
    "#             if i == 0:\n",
    "#                 prev_reward = reward\n",
    "#                 continue\n",
    "                \n",
    "#             reward, prev_reward = prev_reward * 0.99 + reward, reward\n",
    "#             self.short_memory[len(self.short_memory) - 1 - i][2] = reward \n",
    "            \n",
    "        self.short_memory = [x for x in self.short_memory if x[-1] == False]\n",
    "        \n",
    "        if len(self.memory) + len(self.short_memory) < self.capacity:\n",
    "            self.memory.extend(self.short_memory)\n",
    "        else:\n",
    "            for memo in self.short_memory:\n",
    "                self.memory.insert(0, memo)\n",
    "        \n",
    "        self.short_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 8),\n",
    "    torch.nn.LeakyReLU(inplace=True),\n",
    "#     torch.nn.Linear(32, 32),\n",
    "#     torch.nn.LeakyReLU(inplace=True),\n",
    "    torch.nn.Linear(8, 2),\n",
    "#     torch.nn.Sigmoid(),\n",
    "#     torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optim, step_size=30, gamma=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 8),\n",
    "            torch.nn.LeakyReLU(inplace=True),\n",
    "        #     torch.nn.Linear(32, 32),\n",
    "        #     torch.nn.LeakyReLU(inplace=True),\n",
    "            torch.nn.Linear(8, 2),\n",
    "#             torch.nn.Sigmoid(),\n",
    "        #     torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "policy_net = Qnet().to(device)\n",
    "target_net = Qnet().to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optim = torch.optim.Adam(policy_net.parameters(), lr=0.05)\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optim, step_size=30, gamma=0.97)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode   0:     14.000 iterations, eps=0.798801\n",
      "Episode  50:     16.600 iterations, eps=0.727713\n",
      "Episode 100:     14.900 iterations, eps=0.664744\n",
      "Episode 150:     14.000 iterations, eps=0.616217\n",
      "Episode 200:     14.350 iterations, eps=0.569577\n",
      "Episode 250:     12.100 iterations, eps=0.528261\n",
      "Episode 300:     11.600 iterations, eps=0.491758\n",
      "Episode 350:     11.150 iterations, eps=0.458511\n",
      "Episode 400:     11.700 iterations, eps=0.428410\n",
      "Episode 450:     11.650 iterations, eps=0.404106\n",
      "Episode 500:     11.150 iterations, eps=0.380914\n",
      "Episode 550:     10.650 iterations, eps=0.358910\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 2000\n",
    "\n",
    "STEP = 0\n",
    "EPS = 0.8\n",
    "EPS_MIN = 0.05\n",
    "GAMMA = 0.9999\n",
    "\n",
    "\n",
    "def get_model_action(model, state, device, train=True):\n",
    "    global STEP, EPS, EPS_MIN, GAMMA\n",
    "    STEP += 1\n",
    "    EPS = EPS * GAMMA\n",
    "    EPS = max(EPS, EPS_MIN)\n",
    "    \n",
    "    if not train or random.random() > EPS:\n",
    "        with torch.no_grad():\n",
    "            model_output = model(torch.FloatTensor(state).to(device).unsqueeze(0)).cpu().detach().numpy()\n",
    "            action = np.argmax(model_output[0])\n",
    "    else:\n",
    "        action = random.randint(0, 1)\n",
    "    return action\n",
    "\n",
    "def train(model, memory, device):\n",
    "    memory = memory.memory\n",
    "    np.random.shuffle(memory)\n",
    "    memory = memory[:512]\n",
    "    \n",
    "    old = [x[0] for x in memory]\n",
    "    actions = [[x[1]] for x in memory]\n",
    "    rewards = [x[2] for x in memory]\n",
    "    new = [x[3] for x in memory]\n",
    "    \n",
    "    old = torch.FloatTensor(old).to(device)\n",
    "    new = torch.FloatTensor(new).to(device)\n",
    "    rewards = torch.FloatTensor(rewards).to(device)\n",
    "    actions = torch.LongTensor(actions).to(device)\n",
    "    \n",
    "#     print(old)\n",
    "#     print(new)\n",
    "#     print(rewards)\n",
    "#     print(actions)\n",
    "    \n",
    "    \n",
    "    state_action_values = policy_net(old).gather(1, actions)\n",
    "    next_state_values = target_net(new).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * 0.999) + rewards\n",
    "#     print('next', next_state_values)\n",
    "#     print('rew', rewards)\n",
    "#     print('exp', expected_state_action_values)\n",
    "#     assert False\n",
    "    loss = torch.nn.functional.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    \n",
    "    policy_net.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optim.step()\n",
    "\n",
    "#     train_data = []\n",
    "#     for memo in memory:\n",
    "#         old_state, action, reward, new_state, *_ = memo\n",
    "        \n",
    "#         state_value = policy_net(torch.FloatTensor(old_state).to(device).unsqueeze(0)).cpu().detach().numpy()\n",
    "#         state_value = np.argmax(state_value)\n",
    "        \n",
    "#         expected = target_net(torch.FloatTensor(new_state).to(device).unsqueeze(0)).cpu().detach().numpy()\n",
    "#         expected = np.argmax(expected[0])\n",
    "#         expected = expected * 0.96 + reward\n",
    "        \n",
    "        \n",
    "        \n",
    "#         train_data.append([state_value, expected])\n",
    "        \n",
    "#     batch_size = 1024\n",
    "#     np.random.shuffle(train_data)\n",
    "    \n",
    "#     for i in range((len(train_data) // batch_size)):\n",
    "#         policy_net.zero_grad()\n",
    "        \n",
    "#         data = train_data[i*batch_size : i*batch_size + batch_size]\n",
    "#         x, y = [x[0] for x in data], [x[1] for x in data]\n",
    "#         x = torch.FloatTensor(x).to(device)\n",
    "#         y = torch.FloatTensor(x).to(device)\n",
    "# #         output = model(torch.FloatTensor(x).to(device))\n",
    "# #         loss = torch.nn.functional.l1_loss(output, torch.FloatTensor(y).to(device))\n",
    "#         loss = torch.nn.functional.smooth_l1_loss(x, y)\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "memory = Memory(capacity=10000)\n",
    "\n",
    "#get starting actions\n",
    "# for episode in range(100):\n",
    "#     state = env.reset()\n",
    "#     for i in range(100):\n",
    "#         action = env.action_space.sample()\n",
    "#         old_state = state\n",
    "#         state, reward, done, info = env.step(action)\n",
    "        \n",
    "#         memory.push(old_state, action, reward, state)\n",
    "#         state = old_state\n",
    "#         if done:\n",
    "#             env.close()\n",
    "#             break\n",
    "#     memory.commit()\n",
    "        \n",
    "\n",
    "from itertools import count\n",
    "\n",
    "len_mem = []\n",
    "try:\n",
    "    for episode in range(10000):\n",
    "        state = env.reset()\n",
    "\n",
    "        for i in count():\n",
    "#             env.render()\n",
    "\n",
    "            action = get_model_action(policy_net, state, device)\n",
    "            old_state = state\n",
    "            state, reward, done, info = env.step(action)\n",
    "            \n",
    "            memory.push(old_state, action, reward, state)\n",
    "            state = old_state\n",
    "\n",
    "            if done:\n",
    "                env.close()\n",
    "                len_mem.append(i)\n",
    "                memory.commit(final=i!=2000)\n",
    "                break\n",
    "\n",
    "        \n",
    "        if episode % 50 == 0:\n",
    "            print('Episode {:3d}: {:10.3f} iterations, eps={:6.6f}'.format(episode, np.mean(len_mem[-20:]), EPS))\n",
    "        \n",
    "        train(policy_net, memory, device)\n",
    "        \n",
    "        if episode % 1 == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "            \n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5ba48b8908>]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ba5776b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(len_mem, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    env.seed = random.randint(0, 100000)\n",
    "    obs = env.reset()\n",
    "    env._max_episode_steps = 5000\n",
    "    for t in count():\n",
    "        env.render()\n",
    "        action = get_model_action(model, obs, device, train=False)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            env.close()\n",
    "            break\n",
    "\n",
    "    print(t)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    env.close()\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "  (2): Linear(in_features=8, out_features=2, bias=True)\n",
       "  (3): Sigmoid()\n",
       "  (4): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "  (2): Linear(in_features=8, out_features=2, bias=True)\n",
       "  (3): Sigmoid()\n",
       "  (4): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
