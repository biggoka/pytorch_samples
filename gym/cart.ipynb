{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from itertools import count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(2,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, capacity=10000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.short_memory = []\n",
    "        \n",
    "    def push(self, old_state, action, reward, new_state, final):\n",
    "        self.short_memory.append([old_state, action, reward, new_state, final])\n",
    "        \n",
    "    def commit(self, final=True):   \n",
    "        if len(self.memory) + len(self.short_memory) < self.capacity:\n",
    "            self.memory.extend(self.short_memory)\n",
    "        else:\n",
    "            for memo in self.short_memory:\n",
    "                self.memory.insert(random.randint(0, len(self.memory) - 1), memo)\n",
    "                \n",
    "        self.memory = self.memory[:self.capacity]\n",
    "        self.short_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 32),\n",
    "#             torch.nn.LeakyReLU(inplace=True),\n",
    "#             torch.nn.Linear(32, 32),\n",
    "            torch.nn.LeakyReLU(inplace=True),\n",
    "            torch.nn.Linear(32, 3),\n",
    "#             torch.nn.Sigmoid(),\n",
    "        #     torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "policy_net = Qnet().to(device)\n",
    "target_net = Qnet().to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optim = torch.optim.Adam(policy_net.parameters(), lr=0.001)\n",
    "# optim = torch.optim.SGD(policy_net.parameters(), lr=0.001)\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optim, step_size=100, gamma=0.84)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode   0:    199.000 iterations, eps=0.898202\n",
      "Episode 100:    199.000 iterations, eps=0.735385\n",
      "Episode 200:    199.000 iterations, eps=0.602081\n",
      "Episode 300:    199.000 iterations, eps=0.492942\n",
      "Episode 400:    199.000 iterations, eps=0.403586\n",
      "Episode 500:    199.000 iterations, eps=0.330428\n",
      "Episode 600:    199.000 iterations, eps=0.270532\n",
      "Episode 700:    199.000 iterations, eps=0.221492\n",
      "Episode 800:    199.000 iterations, eps=0.181342\n",
      "Episode 900:    199.000 iterations, eps=0.148470\n",
      "Episode 1000:    199.000 iterations, eps=0.121557\n",
      "Episode 1100:    199.000 iterations, eps=0.099523\n",
      "Episode 1200:    199.000 iterations, eps=0.081482\n"
     ]
    }
   ],
   "source": [
    "# env = gym.make('CartPole-v0')\n",
    "# env._max_episode_steps = 500\n",
    "\n",
    "EPS = 0.9\n",
    "EPS_MIN = 0.003\n",
    "GAMMA = 0.99999\n",
    "\n",
    "\n",
    "def get_model_action(model, state, device, train=True):\n",
    "    global EPS, EPS_MIN, GAMMA\n",
    "    EPS = EPS * GAMMA\n",
    "    EPS = max(EPS, EPS_MIN)\n",
    "    \n",
    "    if not train or random.random() > EPS:\n",
    "        with torch.no_grad():\n",
    "            model_output = model(torch.FloatTensor(state).to(device).unsqueeze(0)).cpu().detach().numpy()\n",
    "            action = np.argmax(model_output[0])\n",
    "#             print(state, model_output, action)\n",
    "            \n",
    "    else:\n",
    "        action = random.randint(0, 2)\n",
    "    return action\n",
    "\n",
    "def train(model, memory, device):\n",
    "    memory = memory.memory\n",
    "    try:\n",
    "        memory = random.sample(memory, 1024)\n",
    "    except ValueError:\n",
    "        return\n",
    "\n",
    "    s0 = [x[0] for x in memory]\n",
    "    a = [x[1] for x in memory]\n",
    "    r = [x[2] for x in memory]\n",
    "    s1 = [x[3] for x in memory]\n",
    "    done = [1. if x[4] else 0. for x in memory]\n",
    "\n",
    "\n",
    "    s0 = torch.FloatTensor(s0).to(device)\n",
    "    s1 = torch.FloatTensor(s1).to(device)\n",
    "    a = torch.LongTensor(a).to(device)\n",
    "    r = torch.FloatTensor(r).to(device)\n",
    "    done = torch.FloatTensor(done).to(device)\n",
    "\n",
    "    q_values = policy_net(s0)\n",
    "    next_q_values = target_net(s1)\n",
    "    next_q_value = next_q_values.max(1)[0]\n",
    "\n",
    "    q_value = q_values.gather(1, a.unsqueeze(1)).squeeze(1)\n",
    "    expected_q_value = r + 0.999 * next_q_value * (1.0 - done)\n",
    "    # Notice that detach the expected_q_value\n",
    "#     loss = (expected_q_value.detach() - q_value).pow(2).mean()\n",
    "    loss = torch.nn.functional.smooth_l1_loss(expected_q_value.detach(), q_value)\n",
    "\n",
    "    optim.zero_grad()\n",
    "#     torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "        \n",
    "#     scheduler.step()\n",
    "\n",
    "memory = Memory(capacity=100000)  \n",
    "len_mem = []\n",
    "\n",
    "try:\n",
    "    for episode in range(100000):\n",
    "        state = env.reset()\n",
    "\n",
    "        for i in count():\n",
    "#             env.render()\n",
    "\n",
    "            action = get_model_action(policy_net, state, device)\n",
    "            old_state = state\n",
    "            state, reward, done, info = env.step(action)\n",
    "            \n",
    "#             reward = max(0, state[0]*10)\n",
    "            \n",
    "#             reward = -1 + max(0, state[0]*10)\n",
    "    \n",
    "            if not done:\n",
    "                memory.push(old_state, action, reward, state, False)\n",
    "            else:\n",
    "                env.close()\n",
    "                len_mem.append(i)\n",
    "                \n",
    "#                 if state[0] >= 0.59:\n",
    "#                     reward = 100\n",
    "#                     final = False\n",
    "#                 else:\n",
    "#                     final = True\n",
    "                \n",
    "                memory.push(old_state, action, reward, state, True)\n",
    "                memory.commit()\n",
    "                break\n",
    "\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            print('Episode {:3d}: {:10.3f} iterations, eps={:6.6f}'.format(episode, np.mean(len_mem[-50:]), EPS))\n",
    "        \n",
    "        train(policy_net, memory, device)\n",
    "        \n",
    "        if episode % 10 == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "            \n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f04e415aac8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04eee847f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(len_mem, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "199\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "#     env.seed = random.randint(0, 100000)\n",
    "    obs = env.reset()\n",
    "#     env._max_episode_steps = 100000\n",
    "    for t in count():\n",
    "        \n",
    "        if t % 500 == 0:\n",
    "            print(t)\n",
    "        \n",
    "        env.render()\n",
    "        global EPS\n",
    "        EPS = 0.95\n",
    "        action = get_model_action(policy_net, obs, device, train=False)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            env.close()\n",
    "            break\n",
    "\n",
    "    print(t)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    env.close()\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qnet(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Qnet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'cart.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('cart.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qnet(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
